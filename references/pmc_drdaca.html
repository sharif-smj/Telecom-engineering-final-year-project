
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Dual Residual Denoising Autoencoder with Channel Attention Mechanism for Modulation of Signals - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="ABCB93219198A1E3359321003D00F100.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="sensors">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9861137/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Sensors (Basel, Switzerland)">
<meta name="citation_title" content="Dual Residual Denoising Autoencoder with Channel Attention Mechanism for Modulation of Signals">
<meta name="citation_author" content="Ruifeng Duan">
<meta name="citation_author_institution" content="School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China">
<meta name="citation_author_institution" content="Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China">
<meta name="citation_author" content="Ziyu Chen">
<meta name="citation_author_institution" content="School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China">
<meta name="citation_author_institution" content="Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China">
<meta name="citation_author" content="Haiyan Zhang">
<meta name="citation_author_institution" content="School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China">
<meta name="citation_author_institution" content="Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China">
<meta name="citation_author" content="Xu Wang">
<meta name="citation_author_institution" content="School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China">
<meta name="citation_author_institution" content="Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China">
<meta name="citation_author" content="Wei Meng">
<meta name="citation_author_institution" content="School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China">
<meta name="citation_author_institution" content="Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China">
<meta name="citation_author" content="Guodong Sun">
<meta name="citation_author_institution" content="School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China">
<meta name="citation_author_institution" content="Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China">
<meta name="citation_publication_date" content="2023 Jan 16">
<meta name="citation_volume" content="23">
<meta name="citation_issue" content="2">
<meta name="citation_firstpage" content="1023">
<meta name="citation_doi" content="10.3390/s23021023">
<meta name="citation_pmid" content="36679819">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC9861137/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC9861137/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC9861137/pdf/sensors-23-01023.pdf">
<meta name="description" content="Aiming to address the problems of the high bit error rate (BER) of demodulation or low classification accuracy of modulation signals with a low signal-to-noise ratio (SNR), we propose a double-residual denoising autoencoder method with a channel ...">
<meta name="og:title" content="Dual Residual Denoising Autoencoder with Channel Attention Mechanism for Modulation of Signals">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Aiming to address the problems of the high bit error rate (BER) of demodulation or low classification accuracy of modulation signals with a low signal-to-noise ratio (SNR), we propose a double-residual denoising autoencoder method with a channel ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC9861137/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://pmc.ncbi.nlm.nih.gov/search/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="9861137">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.3390/s23021023"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/sensors-23-01023.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC9861137%2F%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/9861137/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/9861137/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC9861137/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-sensors.png" alt="Sensors (Basel, Switzerland) logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Sensors (Basel, Switzerland)" title="Link to Sensors (Basel, Switzerland)" shape="default" href="http://www.mdpi.com/journal/sensors" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sensors (Basel)</button></div>. 2023 Jan 16;23(2):1023. doi: <a href="https://doi.org/10.3390/s23021023" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.3390/s23021023</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://pmc.ncbi.nlm.nih.gov/search/?term=%22Sensors%20(Basel)%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sensors%20(Basel)%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sensors%20(Basel)%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sensors%20(Basel)%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Dual Residual Denoising Autoencoder with Channel Attention Mechanism for Modulation of Signals</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Duan%20R%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Ruifeng Duan</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Ruifeng Duan</span></h3>
<div class="p">
<sup>1</sup>School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China</div>
<div class="p">
<sup>2</sup>Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China</div>
<div>Conceptualization, Methodology, Validation, Writing – original draft, Project administration, Funding acquisition</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Duan%20R%22%5BAuthor%5D" class="usa-link"><span class="name western">Ruifeng Duan</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chen%20Z%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Ziyu Chen</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Ziyu Chen</span></h3>
<div class="p">
<sup>1</sup>School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China</div>
<div class="p">
<sup>2</sup>Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China</div>
<div>Conceptualization, Validation, Data curation, Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chen%20Z%22%5BAuthor%5D" class="usa-link"><span class="name western">Ziyu Chen</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Haiyan Zhang</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Haiyan Zhang</span></h3>
<div class="p">
<sup>1</sup>School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China</div>
<div class="p">
<sup>2</sup>Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China</div>
<div>Methodology, Validation, Formal analysis, Visualization, Project administration</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Haiyan Zhang</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>*</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20X%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Xu Wang</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Xu Wang</span></h3>
<div class="p">
<sup>1</sup>School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China</div>
<div class="p">
<sup>2</sup>Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China</div>
<div>Formal analysis, Writing – original draft</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20X%22%5BAuthor%5D" class="usa-link"><span class="name western">Xu Wang</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Meng%20W%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Wei Meng</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Wei Meng</span></h3>
<div class="p">
<sup>1</sup>School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China</div>
<div class="p">
<sup>2</sup>Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China</div>
<div>Resources, Writing – review &amp; editing, Supervision</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Meng%20W%22%5BAuthor%5D" class="usa-link"><span class="name western">Wei Meng</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sun%20G%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Guodong Sun</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Guodong Sun</span></h3>
<div class="p">
<sup>1</sup>School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China</div>
<div class="p">
<sup>2</sup>Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China</div>
<div>Investigation, Visualization</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sun%20G%22%5BAuthor%5D" class="usa-link"><span class="name western">Guodong Sun</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>
</div>
<div class="cg p">Editor: <span class="name western">Gwanggil Jeon</span>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="af1-sensors-23-01023">
<sup>1</sup>School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China</div>
<div id="af2-sensors-23-01023">
<sup>2</sup>Engineering Research Center for Forestry-Oriented Intelligent Information Processing of National Forestry and Grassland Administration, Beijing 100083, China</div>
<div class="author-notes p"><div class="fn" id="c1-sensors-23-01023">
<sup>*</sup><p class="display-inline">Correspondence: <span>zhyzml@bjfu.edu.cn</span></p>
</div></div>
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Ruifeng Duan</span></strong>: <span class="role">Conceptualization, Methodology, Validation, Writing – original draft, Project administration, Funding acquisition</span>
</div>
<div>
<strong class="contrib"><span class="name western">Ziyu Chen</span></strong>: <span class="role">Conceptualization, Validation, Data curation, Writing – review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Haiyan Zhang</span></strong>: <span class="role">Methodology, Validation, Formal analysis, Visualization, Project administration</span>
</div>
<div>
<strong class="contrib"><span class="name western">Xu Wang</span></strong>: <span class="role">Formal analysis, Writing – original draft</span>
</div>
<div>
<strong class="contrib"><span class="name western">Wei Meng</span></strong>: <span class="role">Resources, Writing – review &amp; editing, Supervision</span>
</div>
<div>
<strong class="contrib"><span class="name western">Guodong Sun</span></strong>: <span class="role">Investigation, Visualization</span>
</div>
<div class="p">
<strong class="contrib"><span class="name western">Gwanggil Jeon</span></strong>: <span class="role">Academic Editor</span>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2022 Nov 15; Revised 2023 Jan 3; Accepted 2023 Jan 13; Collection date 2023 Jan.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2023 by the authors.</div>
<p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://creativecommons.org/licenses/by/4.0/</a>).</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC9861137  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/36679819/" class="usa-link">36679819</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<p>Aiming to address the problems of the high bit error rate (BER) of demodulation or low classification accuracy of modulation signals with a low signal-to-noise ratio (SNR), we propose a double-residual denoising autoencoder method with a channel attention mechanism, referred to as DRdA-CA, to improve the SNR of modulation signals. The proposed DRdA-CA consists of an encoding module and a decoding module. A squeeze-and-excitation (SE) ResNet module containing one residual connection is modified and then introduced into the autoencoder as the channel attention mechanism, to better extract the characteristics of the modulation signals and reduce the computational complexity of the model. Moreover, the other residual connection is further added inside the encoding and decoding modules to optimize the network degradation problem, which is beneficial for fully exploiting the multi-level features of modulation signals and improving the reconstruction quality of the signal. The ablation experiments prove that both the improved SE module and dual residual connections in the proposed method play an important role in improving the denoising performance. The subsequent experimental results show that the proposed DRdA-CA significantly improves the SNR values of eight modulation types in the range of −12 dB to 8 dB. Especially for 16QAM and 64QAM, the SNR is improved by 8.38 dB and 8.27 dB on average, respectively. Compared to the DnCNN denoising method, the proposed DRdA-CA makes the average classification accuracy increase by 67.59∼74.94% over the entire SNR range. When it comes to the demodulation, compared with the RLS and the DnCNN denoising algorithms, the proposed denoising method reduces the BER of 16QAM by an average of 63.5% and 40.5%, and reduces the BER of 64QAM by an average of 46.7% and 18.6%. The above results show that the proposed DRdA-CA achieves the optimal noise reduction effect.</p>
<section id="kwd-group1" class="kwd-group"><p><strong>Keywords:</strong> signal denoising, convolutional autoencoder, channel attention, residual connection, AWGN</p></section></section><section id="sec1-sensors-23-01023"><h2 class="pmc_sec_title">1. Introduction</h2>
<p>The improvement of the SNR plays an important role in both the cooperative and non-cooperative fields of wireless communication systems. In cooperative communication, improving the modulation signal’s SNR can enhance the signal transmission quality and reduce the demodulation error rate. When it comes to non-cooperative communication, the improvement of the SNR is conducive to improving the modulation classification accuracy, and then signal interception or interference can be performed more effectively. Therefore, the denoising method of modulation signals has always been the research focus of wireless communication.</p>
<p>In the traditional signal denoising methods, Parolai et al. in Ref. [<a href="#B1-sensors-23-01023" class="usa-link" aria-describedby="B1-sensors-23-01023">1</a>] use the wavelet transform (WT) denoising method to deal with seismic wave signals, eliminate noise coefficients below the threshold value, and then reconstruct signals through inverse WT. However, it is difficult for the WT denoising method to select the proper parameters, including wavelet base, threshold, and decomposition layers. Milani et al. [<a href="#B2-sensors-23-01023" class="usa-link" aria-describedby="B2-sensors-23-01023">2</a>] use the least mean square (LMS) algorithm to eliminate the noise of acoustic signals, and Albu et al. [<a href="#B3-sensors-23-01023" class="usa-link" aria-describedby="B3-sensors-23-01023">3</a>] use the recursive least squares (RLS) algorithm for signal noise reduction. The RLS algorithm is an improvement on the LMS algorithm and it adopts recursive calculation and has better performance than the LMS adaptive transverse filter. But Haykin et al. [<a href="#B4-sensors-23-01023" class="usa-link" aria-describedby="B4-sensors-23-01023">4</a>] point out that the performance of the RLS algorithm is not stable due to its internal positive feedback mechanism. Li et al., in Refs. [<a href="#B5-sensors-23-01023" class="usa-link" aria-describedby="B5-sensors-23-01023">5</a>,<a href="#B6-sensors-23-01023" class="usa-link" aria-describedby="B6-sensors-23-01023">6</a>,<a href="#B7-sensors-23-01023" class="usa-link" aria-describedby="B7-sensors-23-01023">7</a>], use the principal component analysis (PCA) method to reduce the signal’s noise. The PCA algorithm recombines the original variables into a group of new irrelevant variables by reducing the dimension of the data, and extracts important characteristic variables according to the actual needs. However, it cannot accurately estimate the number of potential hidden variables in signals [<a href="#B8-sensors-23-01023" class="usa-link" aria-describedby="B8-sensors-23-01023">8</a>]. Moreover, the PCA method cannot analyze the principal components accurately when the noise’s energy is greater than the signal’s energy. Bekara et al. [<a href="#B9-sensors-23-01023" class="usa-link" aria-describedby="B9-sensors-23-01023">9</a>,<a href="#B10-sensors-23-01023" class="usa-link" aria-describedby="B10-sensors-23-01023">10</a>] adopt the singular value decomposition (SVD) method for noise reduction and achieve satisfactory results. The SVD algorithm is a generalization of spectral analysis theory on arbitrary matrices, but the selections of its effective rank and the reconstruction matrix have a great influence on the performance of the algorithm, and the matrix decomposition of the SVD algorithm is not highly interpretable. Zhang et al. [<a href="#B11-sensors-23-01023" class="usa-link" aria-describedby="B11-sensors-23-01023">11</a>] propose a noise reduction multi-carrier CDSK chaotic communication system based on Schmidt orthogonalization, and obtain good BER performance only under certain parameter conditions by using a sliding filter to reduce noise. It can be seen that there are still some critical issues in the traditional denoising methods that have not been well-addressed. Most of the methods require researchers to know the channel parameters and obtain the channel transmission characteristics by sending a training sequence, which leads to low transmission efficiency and poor channel utilization.</p>
<p>Recently, deep learning has not only achieved great success in the fields of computer vision and natural language processing, but has also provided a new solution for the noise reduction of modulation signals. Chang et al. [<a href="#B12-sensors-23-01023" class="usa-link" aria-describedby="B12-sensors-23-01023">12</a>] propose a convolutional neural network (CNN)-based hybrid cascade structure to replace the traditional equalizer in the communication system. Wada et al. [<a href="#B13-sensors-23-01023" class="usa-link" aria-describedby="B13-sensors-23-01023">13</a>] use two fully connected layers (FC) as denoising autoencoders to reduce noise of modulation signals. Zhao et al. [<a href="#B14-sensors-23-01023" class="usa-link" aria-describedby="B14-sensors-23-01023">14</a>] propose a deep neural network co-evolving simultaneously at two different scales to enhance the denoising ability of the model. Johanna et al. [<a href="#B15-sensors-23-01023" class="usa-link" aria-describedby="B15-sensors-23-01023">15</a>] use a CNN-based denoising model to suppress interference in real-world radar measurements. Hwanjin Kim et al. [<a href="#B16-sensors-23-01023" class="usa-link" aria-describedby="B16-sensors-23-01023">16</a>] develop and compare a machine learning (ML)-based channel predictor and a vector Kalman filter (VKF)-based channel predictor using the spatial channel model (SCM), which is widely used in the 3GPP standard.</p>
<p>Due to the limitations of the simple network model, the above five methods cannot extract deep signal features, resulting in limited SNR improvement. In deep convolutional networks, shallow convolution can extract detailed edge data, while deep convolution can selectively acquire useful semantic information. Therefore, deep convolutional networks are also widely used in signal denoising. In 2017, Zhang et al. [<a href="#B17-sensors-23-01023" class="usa-link" aria-describedby="B17-sensors-23-01023">17</a>] propose the residual learning of deep CNN for image denoising (DnCNN) and achieve excellent performance. In 2019, Khan et al. [<a href="#B18-sensors-23-01023" class="usa-link" aria-describedby="B18-sensors-23-01023">18</a>] extend the DnCNN method to the field of noise reduction for modulation signals, and experiments show that it has achieved a favorable denoising effect on high-order QAM modulation signals that are susceptible to noise interference. In the same year, Yin et al. [<a href="#B19-sensors-23-01023" class="usa-link" aria-describedby="B19-sensors-23-01023">19</a>] propose a full convolutional denoising autoencoder to reduce the noise of underwater acoustic signals, and obtain better results in both the time domain and frequency domain, compared with traditional methods. Xue et al. [<a href="#B20-sensors-23-01023" class="usa-link" aria-describedby="B20-sensors-23-01023">20</a>] design a wireless signal enhancement network based on the specialized Generative Adversarial Networks, which can adaptively learn the characteristics of signals and realize signal enhancement in time-varying systems. However, such methods ignore the correlation between the deep feature maps and the shallow feature maps, and they often have high training complexity because of deep layers. Refs. [<a href="#B21-sensors-23-01023" class="usa-link" aria-describedby="B21-sensors-23-01023">21</a>,<a href="#B22-sensors-23-01023" class="usa-link" aria-describedby="B22-sensors-23-01023">22</a>,<a href="#B23-sensors-23-01023" class="usa-link" aria-describedby="B23-sensors-23-01023">23</a>,<a href="#B24-sensors-23-01023" class="usa-link" aria-describedby="B24-sensors-23-01023">24</a>,<a href="#B25-sensors-23-01023" class="usa-link" aria-describedby="B25-sensors-23-01023">25</a>,<a href="#B26-sensors-23-01023" class="usa-link" aria-describedby="B26-sensors-23-01023">26</a>] consider the correlation between feature maps of different scales and depths in the model’s design, and the feature graphs of different levels are added by using residual connections [<a href="#B27-sensors-23-01023" class="usa-link" aria-describedby="B27-sensors-23-01023">27</a>], which effectively alleviates the difficulty of training deep network models and resolves the problems of gradient disappearance and explosion. The simple connections between feature maps of different scales and depths still make it difficult to selectively strengthen some important features, degrading the performance of the network model.</p>
<p>The channel attention mechanism is a very powerful method for optimizing network performance. It can selectively strengthen feature values of important channels by changing the weight of the channel, thus improving the expression ability of the network and achieving higher performance. Yancheng et al. [<a href="#B28-sensors-23-01023" class="usa-link" aria-describedby="B28-sensors-23-01023">28</a>] employ the residual encoder-decoder structure and multi-attention mechanism fusion module to perform feature map reuse and self-recalibrating features, which can significantly improve the performance of ultrasound image denoising. Li et al. [<a href="#B29-sensors-23-01023" class="usa-link" aria-describedby="B29-sensors-23-01023">29</a>] propose a new end-to-end semantic segmentation network, which integrates lightweight spatial and channel attention modules that can refine features adaptively. Zhou et al. [<a href="#B30-sensors-23-01023" class="usa-link" aria-describedby="B30-sensors-23-01023">30</a>] propose to incorporate an attention mechanism including a spatial attention module and a channel attention module into a U-Net architecture to re-weight the feature representation spatially and channel-wise to capture rich contextual relationships for better feature representation.</p>
<p>Based on the above analysis, in this paper, we adopt a deep convolutional network to construct a denoising autoencoder, in which more effective residual connections between different scales and depths are explored to extract richer features and optimize network degradation problem. We also try to integrate the squeeze-and-excitation (SE) module [<a href="#B31-sensors-23-01023" class="usa-link" aria-describedby="B31-sensors-23-01023">31</a>] into the network as a typical channel attention mechanism. The SE module can first obtain the global features of each channel in the denoising network through the global average pooling operation [<a href="#B32-sensors-23-01023" class="usa-link" aria-describedby="B32-sensors-23-01023">32</a>], and the global features reflect the correlations between and effectiveness of the channel feature maps. Then, the global features are weighted to make the channel with a strong correlation and high effectiveness have more weight, and vice versa. By selectively strengthening the channel weights and emphasizing the features of important channels, the SE module makes the network have a strong expression ability, leading to superior performance. The contributions of this paper can be summarized as follows.</p>
<ul class="list" style="list-style-type:none">
<li>
<span class="label">(1)</span><p class="display-inline">We choose the convolutional denoising autoencoder as the noise reduction model for modulation signals. Residual connections are added not only inside the encoding (decoding) block but also between the encoding (decoding) blocks of different depths to form a double residual connection.</p>
</li>
<li>
<span class="label">(2)</span><p class="display-inline">The SE module is improved and introduced into the denoising autoencoder to optimize the feature extraction of modulation signals. The improved SE module retains the advantages of selective enhancement for channel features, and the number of parameters is fewer, which makes the network model easier to train and achieve a better noise reduction effect.</p>
</li>
<li>
<span class="label">(3)</span><p class="display-inline">In the decoding module of the denoising autoencoder, transpose convolution (TConv) is selected to complete upsampling. The parameters inside TConv can be initialized randomly and updated iteratively. At the same time, the SmoothL1Loss(SLL) function is used as the loss function of the denoising autoencoder, which can better measure the error between the estimated value and the real value, reconstruct a more accurate modulation signal, and improve the accuracy of the model training.</p>
</li>
</ul>
<p>The remainder of this paper is organized as follows. <a href="#sec2-sensors-23-01023" class="usa-link">Section 2</a> describes the communication system model. <a href="#sec3-sensors-23-01023" class="usa-link">Section 3</a> analyzes the applicability of the neural network and introduces the principles and details of the proposed DRdA-CA. <a href="#sec4-sensors-23-01023" class="usa-link">Section 4</a> describes the dataset generation and preprocessing. The simulation results and performance analysis are summarized in <a href="#sec5-sensors-23-01023" class="usa-link">Section 5</a>. Finally, <a href="#sec6-sensors-23-01023" class="usa-link">Section 6</a> concludes the paper.</p></section><section id="sec2-sensors-23-01023"><h2 class="pmc_sec_title">2. Communication System Model</h2>
<p>In this paper, we focus on the communication scenarios under the additive white Gaussian noise (AWGN) channel [<a href="#B33-sensors-23-01023" class="usa-link" aria-describedby="B33-sensors-23-01023">33</a>] with a low SNR. The AWGN channel is a widely used channel model between the transmitter and the receiver in wireless communication systems, in which the noise random variable obeys the zero-mean Gaussian distribution. We consider cooperative communication systems and non-cooperative communications systems and the modulation types of the systems are diversified. The system model is shown in <a href="#sensors-23-01023-f001" class="usa-link">Figure 1</a>. At the transmitter, the source bit is modulated and sent to the channel, in which the modulation signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm1" overflow="linebreak"><mrow><mrow><mi>s</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></math></span> will be affected by AWGN.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f001"><h3 class="obj_head">Figure 1.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g001.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/547b75cbd74c/sensors-23-01023-g001.jpg" loading="lazy" height="338" width="793" alt="Figure 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Communication system model.</p></figcaption></figure><p>The received modulation signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm2" overflow="linebreak"><mrow><mrow><msup><mi>s</mi><mo>′</mo></msup><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></mrow></math></span> can be expressed as Equation (<a href="#FD1-sensors-23-01023" class="usa-link">1</a>).
</p>
<table class="disp-formula p" id="FD1-sensors-23-01023"><tr>
<td class="formula"><math id="mm3" display="block" overflow="linebreak"><mrow><mrow><msup><mi>s</mi><mo>′</mo></msup><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>=</mo><mi>s</mi><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>+</mo><mi>n</mi><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="label">(1)</td>
</tr></table>
<p>
where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm4" overflow="linebreak"><mrow><mrow><mi>s</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></math></span> is the modulation signal with IQ components and generated at transmitter and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm5" overflow="linebreak"><mrow><mrow><mi>n</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></math></span> represents zero-mean complex AWGN vector with variance <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm6" overflow="linebreak"><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow></math></span> in each signal dimension. When the noise interference is serious, the received signal quality is very poor, which will badly affect the demodulation performance. In this case, the noise reduction needs to be performed before subsequent processing. In the cooperative communication scenario, the modulation type is known in advance for the receiver, thus the denoised signal will be demodulated directly. For the application of non-cooperative communication, the receiver does not know the current modulation type, thus it needs to firstly perform modulation recognition, as shown in the dashed box in the <a href="#sensors-23-01023-f001" class="usa-link">Figure 1</a>. We chose the automatic modulation classification (AMC) module proposed in [<a href="#B34-sensors-23-01023" class="usa-link" aria-describedby="B34-sensors-23-01023">34</a>] to finish the modulation recognition.</p>
<p>This paper focuses on signal denoising based on deep learning, which corresponds to the denoising network module in <a href="#sensors-23-01023-f001" class="usa-link">Figure 1</a>. We will develop a novel network architecture for noise reduction of multiple modulated signals. Based on the above analysis, eight modulated signals, which are in good agreement with the communication system model described in our paper, are generated using MATLAB software simulation.</p></section><section id="sec3-sensors-23-01023"><h2 class="pmc_sec_title">3. DRdA-CA Architecture Details</h2>
<section id="sec3dot1-sensors-23-01023"><h3 class="pmc_sec_title">3.1. The Proposed Denoising Autoencoder Structure</h3>
<p>This paper proposes a dual residual denoising autoencoder with a channel attention mechanism, and the network model can be seen in <a href="#sensors-23-01023-f002" class="usa-link">Figure 2</a>, which is composed of an encoding module and decoding module in series. The encoding module consists of a <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm7" overflow="linebreak"><mrow><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow></mrow></math></span> convolutional layer and three encoding blocks, and each encoding block is the improved SE-ResNet module. Similarly, the decoding module is also composed of a <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm8" overflow="linebreak"><mrow><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow></mrow></math></span> convolutional layer and three decoding blocks. It is worth noting that, in the encoding and decoding modules, we further introduce the residual connection between encoding (decoding) blocks at different levels to optimize the network degradation problem.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f002"><h4 class="obj_head">Figure 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/bc26288a7ce9/sensors-23-01023-g002.jpg" loading="lazy" height="344" width="780" alt="Figure 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Dual residual denoising autoencoder network framework with channel attention.</p></figcaption></figure><p>This paper focuses on the AWGN channel, and the received modulation signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm9" overflow="linebreak"><mrow><mrow><msup><mi>s</mi><mo>′</mo></msup><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></mrow></math></span> can be expressed as Equation (<a href="#FD1-sensors-23-01023" class="usa-link">1</a>). The task of the noise reduction autoencoder is to obtain the optimal estimation <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm10" overflow="linebreak"><mrow><mrow><msup><mi>s</mi><mo>″</mo></msup><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></mrow></math></span> of the pure modulation signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm11" overflow="linebreak"><mrow><mrow><mi>s</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></math></span> from the <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm12" overflow="linebreak"><mrow><mrow><msup><mi>s</mi><mo>′</mo></msup><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></mrow></math></span>.</p>
<p>In the decoding modules of the proposed DRdA-CA, the Tanh function defined by Equation (<a href="#FD2-sensors-23-01023" class="usa-link">2</a>) is used as the activation function of the convolution layer, which is the output layer.
</p>
<table class="disp-formula p" id="FD2-sensors-23-01023"><tr>
<td class="formula"><math id="mm13" display="block" overflow="linebreak"><mrow><mrow><msub><mi>f</mi><mrow><mi>T</mi><mi>a</mi><mi>n</mi><mi>h</mi></mrow></msub><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msup></mrow><mrow><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msup></mrow></mfrac><mspace width="1.em"></mspace></mrow></mrow></math></td>
<td class="label">(2)</td>
</tr></table>
<p>
where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm14" overflow="linebreak"><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow></math></span> is the input variable. The detailed network parameters of the proposed DRdA-CA are shown in <a href="#sensors-23-01023-t001" class="usa-link">Table 1</a>.</p>
<section class="tw xbox font-sm" id="sensors-23-01023-t001"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Denoising Autoencoder’s Parameters.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Layer Name</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Output Feature Map Size</th>
</tr></thead>
<tbody>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">convolutional layer 1</td>
<td align="center" valign="middle" rowspan="1" colspan="1">32 × 2 × 1024</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">encoding block 1</td>
<td align="center" valign="middle" rowspan="1" colspan="1">32 × 2 × 1024</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">encoding block 2</td>
<td align="center" valign="middle" rowspan="1" colspan="1">64 × 2 × 512</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">encoding block 3</td>
<td align="center" valign="middle" rowspan="1" colspan="1">128 × 1 × 256</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">decoding block 1</td>
<td align="center" valign="middle" rowspan="1" colspan="1">128 × 2 × 521</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">decoding block 2</td>
<td align="center" valign="middle" rowspan="1" colspan="1">64 × 2 × 1024</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">decoding block 3</td>
<td align="center" valign="middle" rowspan="1" colspan="1">32 × 2 × 1024</td>
</tr>
<tr>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">convolutional layer 2</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 × 2 × 1024</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/sensors-23-01023-t001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec3dot2-sensors-23-01023"><h3 class="pmc_sec_title">3.2. The Encoding and Decoding Blocks</h3>
<p>The Squeeze-and-Excitation Deep Residual Network (SE-ResNet), as the champion model of Imagenet 2017, is very similar to the Deep Residual Network (ResNet). However, it adds an SE module so that the information between the channels can be exchanged, thereby improving the performance of the network. <a href="#sensors-23-01023-f003" class="usa-link">Figure 3</a>a depicts the original SE-ResNet module. We modify the SE unit in SE-ResNet and use the improved SE-ResNet to establish the encoding and decoding blocks. That is, the fully connected layer (FC) in the original SE unit is replaced by a convolutional layer. This can be attributed as follows. (1) The SE-ResNet was originally designed and implemented under the Caffe framework, in which the FC supports the input of data dimension <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm15" overflow="linebreak"><mrow><mrow><mn>1</mn><mo>×</mo><mn>1</mn><mo>×</mo><mi>C</mi></mrow></mrow></math></span>. However, the deep learning framework Pytorch used in this paper does not support the input of data with the same dimension. When the FC is used in the model, both the input and output data require dimension transformation, i.e., three-dimensional data <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm16" overflow="linebreak"><mrow><mrow><mn>1</mn><mo>×</mo><mn>1</mn><mo>×</mo><mi>C</mi></mrow></mrow></math></span> should be reduced and flattened into one-dimensional data C as the input of the fully connected layer. It will increase the computational complexity of the model and destroy the spatial structure of the data, leading to the loss of feature information. This problem can be addressed by replacing the FC with a <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm17" overflow="linebreak"><mrow><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></mrow></math></span> convolutional layer. (2) Both the convolutional layer and FC perform a dot product operation on the feature maps, thus they have the same functional form. That is, the <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm18" overflow="linebreak"><mrow><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></mrow></math></span> convolutional layer can be used to replace the FC without changing the function operation of the SE module itself. In addition, since the value of the modulation signals is bipolar with positive and negative numbers, we choose LeakyReLU as the activation function. The improved SE module, as shown in <a href="#sensors-23-01023-f003" class="usa-link">Figure 3</a>b, mainly consists of the following two parts.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f003"><h4 class="obj_head">Figure 3.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g003.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/96da4567973e/sensors-23-01023-g003.jpg" loading="lazy" height="311" width="759" alt="Figure 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Improved SE-Resnet and Original SE-Resnet modules. “⊕” represents addition operation. (<strong>a</strong>) Original SE-ResNet module. (<strong>b</strong>) Improved SE-ResNet module (encoding block).</p></figcaption></figure><p>(1) The squeeze part: Assume that the dimension of the original feature map is <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm19" overflow="linebreak"><mrow><mrow><mi>C</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow></mrow></math></span>, where <em>C</em> represents the number of channels in the feature map, <em>H</em> represents the height of the feature map, and <em>W</em> is the width of the feature map. The task of the squeeze part is to compress the feature map dimension <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm20" overflow="linebreak"><mrow><mrow><mi>C</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow></mrow></math></span> to <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm21" overflow="linebreak"><mrow><mrow><mi>C</mi><mo>×</mo><mn>1</mn><mo>×</mo><mn>1</mn></mrow></mrow></math></span>, which is equivalent to squeezing the matrix in the dimension of of <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm22" overflow="linebreak"><mrow><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow></mrow></math></span> into the matrix in the dimension of <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm23" overflow="linebreak"><mrow><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></mrow></math></span>. The squeezed matrix can still obtain the previous global field of view and has a wider perception area.</p>
<p>The squeeze operation is implemented using the Global Average Pooling (GAP) method, and its calculation is described as follows: </p>
<table class="disp-formula p" id="FD3-sensors-23-01023"><tr>
<td class="formula"><math id="mm24" display="block" overflow="linebreak"><mrow><mrow><msub><mi>g</mi><mi>c</mi></msub><mo>=</mo><msub><mi>F</mi><mrow><mi>s</mi><mi>q</mi></mrow></msub><mrow><mo>(</mo><msub><mi>v</mi><mi>c</mi></msub><mo>)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow></mfrac><mspace width="1.em"></mspace><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>H</mi></munderover><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>W</mi></munderover><msub><mi>v</mi><mi>c</mi></msub><mrow><mo>(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="label">(3)</td>
</tr></table>
<p>
where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm25" overflow="linebreak"><mrow><msub><mi>v</mi><mi>c</mi></msub></mrow></math></span> is the feature map output by the third convolutional layer in the improved SE module. After GAP processing for <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm26" overflow="linebreak"><mrow><msub><mi>v</mi><mi>c</mi></msub></mrow></math></span>, we get the feature map <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm27" overflow="linebreak"><mrow><msub><mi>g</mi><mi>c</mi></msub></mrow></math></span>, and the same below.</p>
<p>(2) The excitation part: By adding a convolutional layer above and below the nonlinear activation layers, we parameterize the gating mechanism to predict the importance of each channel in the feature map <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm28" overflow="linebreak"><mrow><msub><mi>g</mi><mi>c</mi></msub></mrow></math></span>. Then the weight values of different channels are obtained and applied to the original feature map to complete the excitation. The excitation operation process is performed as follows. First, the compressed feature map <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm29" overflow="linebreak"><mrow><msub><mi>g</mi><mi>c</mi></msub></mrow></math></span> is fed into a convolutional layer with <em>C</em>/<em>r</em> output channels, namely a dimensionality-reduction layer with reduction ratio <em>r</em>. Then the convolution result is activated using the LeakyReLU function, and finally the activated feature graph is dimensionally augmented through a convolution layer with <em>C</em> output channels to guarantee channel dimensional consistency between the output <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm30" overflow="linebreak"><mrow><msub><mi>s</mi><mi>c</mi></msub></mrow></math></span> and feature map <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm31" overflow="linebreak"><mrow><msub><mi>v</mi><mi>c</mi></msub></mrow></math></span>. The excitation function <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm32" overflow="linebreak"><mrow><msub><mi>F</mi><mrow><mi>e</mi><mi>x</mi></mrow></msub></mrow></math></span> is given by
</p>
<table class="disp-formula p" id="FD4-sensors-23-01023"><tr>
<td class="formula"><math id="mm33" display="block" overflow="linebreak"><mrow><mrow><msub><mi>s</mi><mi>c</mi></msub><mo>=</mo><msub><mi>F</mi><mrow><mi>e</mi><mi>x</mi></mrow></msub><mrow><mo>(</mo><msub><mi>g</mi><mi>c</mi></msub><mo>,</mo><mi>W</mi><mo>)</mo></mrow><mo>=</mo><mi>σ</mi><mrow><mo>(</mo><msub><mi>W</mi><mn>2</mn></msub><mi>δ</mi><mrow><mo>(</mo><msub><mi>W</mi><mn>1</mn></msub><msub><mi>g</mi><mi>c</mi></msub><mo>)</mo></mrow><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="label">(4)</td>
</tr></table>
<p>
where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm34" overflow="linebreak"><mrow><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mfrac><mi>C</mi><mi>r</mi></mfrac><mo>×</mo><mi>C</mi></mrow></msup></mrow></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm35" overflow="linebreak"><mrow><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>C</mi><mo>×</mo><mfrac><mi>C</mi><mi>r</mi></mfrac></mrow></msup></mrow></mrow></math></span> are the weight values of the two convolutional layers around the LeakyReLU layer, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm36" overflow="linebreak"><mrow><mi>δ</mi></mrow></math></span> is the LeakyReLU function with slope parameter <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm37" overflow="linebreak"><mrow><mrow><mi>α</mi><mo>=</mo><mn>0.001</mn></mrow></mrow></math></span>. The LeakyReLU function solves the problem of neuron necrosis in the ReLU function, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm38" overflow="linebreak"><mrow><mi>σ</mi></mrow></math></span> represents the sigmoid activation function. Finally, the feature map <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm39" overflow="linebreak"><mrow><msub><mi>s</mi><mi>c</mi></msub></mrow></math></span> output by the sigmoid function is used to adjust the channel weights of feature map <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm40" overflow="linebreak"><mrow><msub><mi>v</mi><mi>c</mi></msub></mrow></math></span>, and the calculation process is given by
</p>
<table class="disp-formula p" id="FD5-sensors-23-01023"><tr>
<td class="formula"><math id="mm41" display="block" overflow="linebreak"><mrow><mrow><mover accent="true"><mi>x</mi><mo>˜</mo></mover><mo>=</mo><msub><mi>F</mi><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi></mrow></msub><mrow><mo>(</mo><msub><mi>v</mi><mi>c</mi></msub><mo>,</mo><msub><mi>s</mi><mi>c</mi></msub><mo>)</mo></mrow><mo>=</mo><msub><mi>s</mi><mi>c</mi></msub><msub><mi>v</mi><mi>c</mi></msub></mrow></mrow></math></td>
<td class="label">(5)</td>
</tr></table>
<p>Based on above analysis, the excitation operation can map the feature map <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm42" overflow="linebreak"><mrow><msub><mi>g</mi><mi>c</mi></msub></mrow></math></span> to a set of channel weights <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm43" overflow="linebreak"><mrow><msub><mi>v</mi><mi>c</mi></msub></mrow></math></span>.</p>
<p>The decoding block of the noise reduction autoencoder is depicted in the <a href="#sensors-23-01023-f004" class="usa-link">Figure 4</a>. It is clear that the decoding block is similar to the encoding block, but it adopts TConv instead of one of the convolution layers in the original encoding block to realize the upsampling operation. Like the convolution operation, TConv is learnable. The advantage of transpose convolution is that it can theoretically obtain the upsampled value that is most suitable for the current dataset through continuously updating the parameters.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f004"><h4 class="obj_head">Figure 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g004.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/d4030b06792b/sensors-23-01023-g004.jpg" loading="lazy" height="613" width="680" alt="Figure 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Decoding block.</p></figcaption></figure></section><section id="sec3dot3-sensors-23-01023"><h3 class="pmc_sec_title">3.3. Loss Function</h3>
<p>In the existing work, most denoising autoencoders use the two loss functions of Mean Absolute Error (MAE) and Mean Square Error (MSE), and carry out parameter estimation by minimizing the error. MAE is the average absolute value of the true value minus the predicted value. By contrast, MSE is the average square of the absolute value of the predicted value minus the true value. Both MSE and MAE range from 0 to infinity, and they can be calculated, respectively, using
</p>
<table class="disp-formula p" id="FD6-sensors-23-01023"><tr>
<td class="formula"><math id="mm44" display="block" overflow="linebreak"><mrow><mrow><mi>M</mi><mi>A</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><mspace width="1.em"></mspace><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mo>|</mo><mrow><mo>(</mo><msub><mi>s</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup><mo>)</mo></mrow><mo>|</mo></mrow></mrow></mrow></math></td>
<td class="label">(6)</td>
</tr></table>
<table class="disp-formula p" id="FD7-sensors-23-01023"><tr>
<td class="formula"><math id="mm45" display="block" overflow="linebreak"><mrow><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><mspace width="1.em"></mspace><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mrow><mo>|</mo><mrow><mo>(</mo><msub><mi>s</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup><mo>)</mo></mrow><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></math></td>
<td class="label">(7)</td>
</tr></table>
<p>
where <em>N</em> is the length of the input signal, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm46" overflow="linebreak"><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow></math></span> is the noise-free signal value, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm47" overflow="linebreak"><mrow><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup></mrow></math></span> is the signal-reconstructed value (predicted value) output from our autoencoder, the same as below. The problem existing in the MAE training process is that the update gradient is always the same. Even for a small loss value, the gradient is relatively large, which is not conducive to a training model. Unlike MAE, MSE will assign more weight to outliers, and, at the expense of the error of other samples, the model will be updated towards reducing the error of the outliers, which will result in the performance degradation of the model. In order to overcome the above defects and make the output of the denoising autoencoder more accurate, the SLL is adopted in the proposed DRdA-CA in this paper. The SLL is calculated as follows: </p>
<table class="disp-formula p" id="FD8-sensors-23-01023"><tr>
<td class="formula"><math id="mm48" display="block" overflow="linebreak"><mrow><mrow><mi>S</mi><mi>L</mi><mi>L</mi><mrow><mo>(</mo><mi>s</mi><mo>,</mo><msup><mi>s</mi><mo>″</mo></msup><mo>)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>z</mi><mi>i</mi></msub></mrow></mrow></math></td>
<td class="label">(8)</td>
</tr></table>
<p>
where the variable <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm49" overflow="linebreak"><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow></math></span> is defined as follows: </p>
<table class="disp-formula p" id="FD9-sensors-23-01023"><tr>
<td class="formula"><math id="mm50" display="block" overflow="linebreak"><mrow><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mfenced separators="" open="{" close=""><mtable><mtr><mtd columnalign="left"><mrow><mrow><mn>0.5</mn><mo>×</mo><mo>|</mo></mrow><msub><mi>s</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup><msup><mrow><mo>|</mo></mrow><mn>2</mn></msup><mo>,</mo><mi>if</mi><mrow><mo>|</mo><msub><mi>s</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup><mo>|</mo></mrow><mo>&lt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mrow><mo>|</mo></mrow><msub><mi>s</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup><mrow><mo>|</mo><mo>−</mo><mn>0.5</mn><mo>,</mo><mi>otherwise</mi></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></mrow></math></td>
<td class="label">(9)</td>
</tr></table>
<p>It is clear that SLL is an integration of MSE and MAE. When taking the derivative of SLL, we have: </p>
<table class="disp-formula p" id="FD10-sensors-23-01023"><tr>
<td class="formula"><math id="mm51" display="block" overflow="linebreak"><mrow><mrow><mfrac><mrow><mi mathvariant="normal">d</mi><mi>S</mi><mi>S</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">d</mi><msub><mi>s</mi><mi>i</mi></msub></mrow></mfrac><mspace width="1.em"></mspace><mo>=</mo><mfenced separators="" open="{" close=""><mtable><mtr><mtd columnalign="left"><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>,</mo><mi>if</mi><mrow><mo>|</mo><msub><mi>s</mi><mi>i</mi></msub><mo>|</mo></mrow><mo>&lt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mo>±</mo><mn>1</mn><mo>,</mo><mi>otherwise</mi></mrow></mtd></mtr></mtable></mfenced></mrow></mrow></math></td>
<td class="label">(10)</td>
</tr></table>
<p>In Equation (<a href="#FD10-sensors-23-01023" class="usa-link">10</a>), it can be seen that, when <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm52" overflow="linebreak"><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow></math></span> is small, the derivative of SSL with respect to <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm53" overflow="linebreak"><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow></math></span> also becomes small. Otherwise, the absolute value of the derivative reaches the upper bound of 1, and the network stability will not be impacted by the large derivative. As we know, MSE has derivatives at the origin and is easy to converge, and, in the boundary area, MAE enables our denoising autoecoder to correct back when the error tends to be large. Regarding the two error metrics, therefore, the SLL is more robust with respect to outliers.</p></section></section><section id="sec4-sensors-23-01023"><h2 class="pmc_sec_title">4. Dataset</h2>
<section id="sec4dot1-sensors-23-01023"><h3 class="pmc_sec_title">4.1. Experimental Data and Environment</h3>
<p>The dataset of the denoising autoencoder includes eight modulation signals generated by MATLAB; they are BPSK, QPSK, 8PSK, CPFSK, GMSK, OQPSK, 16QAM, and 64QAM, and the detailed parameters of the dataset are shown in <a href="#sensors-23-01023-t002" class="usa-link">Table 2</a>. The SNR of the modulation signals ranges from −12 dB to 8 dB, and the SNR interval is 2 dB. In the transmission process of the signal, the transmitter completes the modulation and up-conversion of the signal, and then transmits radio frequency signals into the channel. The receiver first performs down-conversion, and subsequently estimates the carrier frequency and phase, restores the received signal to the baseband signal, and performs modulation recognition, demodulation, and other operations. Without the loss of generality, this paper takes the baseband signal as an example to generate the dataset of the modulation signals. The rate of the baseband signal is set to 256 kHz, and the sampling frequency of the signal is 1024 kHz—that is, the oversampling rate of the signal is 4 times higher to increase the fault tolerance rate of the signal. The modulated signals are shaped and filtered using a root raised cosine filter with a roll-off factor of 0.3, and the transmission channel is modelled as an AWGN channel. Pytorch is used as the deep learning framework, and an NVIDIA GeForce RTX2080 Ti graphics card is used to implement the GPU parallel acceleration calculation.</p>
<section class="tw xbox font-sm" id="sensors-23-01023-t002"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Parameter settings for data sample sets.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Parameter</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Value/Description</th>
</tr></thead>
<tbody>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">SNR</td>
<td align="center" valign="middle" rowspan="1" colspan="1">−12:2:8 (dB)</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">Symbol rate</td>
<td align="center" valign="middle" rowspan="1" colspan="1">256k Baud</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">Sample rate</td>
<td align="center" valign="middle" rowspan="1" colspan="1">1024 kHz</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">Oversampling rate</td>
<td align="center" valign="middle" rowspan="1" colspan="1">4</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">Forming filters</td>
<td align="center" valign="middle" rowspan="1" colspan="1">Root raised cosine filter</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">Roll-off factor</td>
<td align="center" valign="middle" rowspan="1" colspan="1">0.3</td>
</tr>
<tr>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Channel</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AWGN channel</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/sensors-23-01023-t002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec4dot2-sensors-23-01023"><h3 class="pmc_sec_title">4.2. Dataset Preprocessing</h3>
<p>In order to facilitate the addition of noise and the measurement of the SNR, as well as to accelerate the training of the model and reduce the computational complexity of the data, we normalize the power of the modulation signals generated by MATLAB simulation using the following formulae: </p>
<table class="disp-formula p" id="FD11-sensors-23-01023"><tr>
<td class="formula"><math id="mm54" display="block" overflow="linebreak"><mrow><mrow><msub><mi>P</mi><mi>s</mi></msub><mo>=</mo><mfrac><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mrow><mo>|</mo><msub><mi>s</mi><mi>i</mi></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mi>N</mi></mfrac><mspace width="1.em"></mspace></mrow></mrow></math></td>
<td class="label">(11)</td>
</tr></table>
<table class="disp-formula p" id="FD12-sensors-23-01023"><tr>
<td class="formula"><math id="mm55" display="block" overflow="linebreak"><mrow><mrow><msub><mi>N</mi><mi>s</mi></msub><mo>=</mo><mfrac><mi>S</mi><msqrt><msub><mi>P</mi><mi>s</mi></msub></msqrt></mfrac><mspace width="1.em"></mspace></mrow></mrow></math></td>
<td class="label">(12)</td>
</tr></table>
<p>
where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm56" overflow="linebreak"><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow></math></span> is the initial noise-free modulation signal, <em>N</em> is the length of the signal, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm57" overflow="linebreak"><mrow><msub><mi>P</mi><mi>s</mi></msub></mrow></math></span> is the signal power, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm58" overflow="linebreak"><mrow><msub><mi>N</mi><mi>s</mi></msub></mrow></math></span> is the noise-free modulation signal with normalized power. In the training stage of the denoising autoencoder, the signal dataset with 11 different SNR values is made into an IQ data sample with the shape of 2 × 1024 for each piece. We split the training set and the values set by the ratio of approximately 8:2, and there are 70,400 pieces of training data and 17,600 pieces of validation data. Then we generate 8800 pieces of test data under the same parameters. The Adaptive Moment Estimation (Adam) optimization algorithm is used to complete model training with 40 training epochs, and the initial learning rate is set to 0.001 while decreasing by 0.1 times every 20 epochs.</p></section></section><section id="sec5-sensors-23-01023"><h2 class="pmc_sec_title">5. Experiment and Analysis</h2>
<section id="sec5dot1-sensors-23-01023"><h3 class="pmc_sec_title">5.1. Layer Number Optimization</h3>
<p>We conduct simulation experiments to evaluate our denoising autoencoder, and we also compare it with a set of typical models including RLS, LMS, PCA, and the deep learning method DnCNN proposed by Khan et al. [<a href="#B18-sensors-23-01023" class="usa-link" aria-describedby="B18-sensors-23-01023">18</a>]. The evaluation metrics are SNR, Error Vector Magnitude (EVM), and demodulation BER before and after noise reduction. In addition, the modulation recognition accuracy is considered and the modulation recognition model is the CNN [<a href="#B34-sensors-23-01023" class="usa-link" aria-describedby="B34-sensors-23-01023">34</a>].</p>
<p>The SNR is defined as the ratio of noiseless signal power to noise power, which can intuitively measure the quality of signal. The calculation formula is given by the following: </p>
<table class="disp-formula p" id="FD13-sensors-23-01023"><tr>
<td class="formula"><math id="mm59" display="block" overflow="linebreak"><mrow><mrow><mi>S</mi><mi>N</mi><msub><mi>R</mi><mrow><mi>d</mi><mi>B</mi></mrow></msub><mo>=</mo><mn>10</mn><mo form="prefix">lg</mo><mrow><mo stretchy="false">(</mo><mfrac><msubsup><mrow><mo>|</mo><mo>|</mo><mi>s</mi><mo>|</mo><mo>|</mo></mrow><mn>2</mn><mn>2</mn></msubsup><mrow><mrow><mo>|</mo><mo>|</mo></mrow><msup><mi>s</mi><mo>′</mo></msup><mo>−</mo><mi>s</mi><msubsup><mrow><mo>|</mo><mo>|</mo></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></mfrac><mspace width="1.em"></mspace><mo stretchy="false">)</mo></mrow></mrow></mrow></math></td>
<td class="label">(13)</td>
</tr></table>
<p>
where <em>s</em> represents the noiseless modulation signal, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm60" overflow="linebreak"><mrow><msup><mi>s</mi><mo>′</mo></msup></mrow></math></span> represents the noisy modulation signal. The parameter EVM can comprehensively measure the amplitude error and phase error of the modulation signal, which is defined as the ratio of the root mean square value of the error vector signal and the root mean square value of the ideal signal, and expressed in the form of a percentage. The calculation formula is given by the following: </p>
<table class="disp-formula p" id="FD14-sensors-23-01023"><tr>
<td class="formula"><math id="mm61" display="block" overflow="linebreak"><mrow><mrow><mi>E</mi><mi>V</mi><mi>M</mi><mo>=</mo><msqrt><mfrac><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mstyle mathsize="50%" displaystyle="true"><munderover><mo>∑</mo><mstyle mathsize="100%" displaystyle="true"><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></mstyle><mstyle mathsize="100%" displaystyle="true"><mi>N</mi></mstyle></munderover></mstyle><mrow><mrow><mo>|</mo></mrow><msub><mi>s</mi><mi>i</mi></msub><mo>−</mo><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup><msup><mrow><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mstyle mathsize="50%" displaystyle="true"><munderover><mo>∑</mo><mstyle mathsize="100%" displaystyle="true"><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></mstyle><mstyle mathsize="100%" displaystyle="true"><mi>N</mi></mstyle></munderover></mstyle><mrow><mo>|</mo><msub><mi>s</mi><mi>i</mi></msub><msup><mrow><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mfrac></msqrt><mo>×</mo><mn>100</mn><mo>%</mo></mrow></mrow></math></td>
<td class="label">(14)</td>
</tr></table>
<p>
where <em>s</em> is the same as before, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="mm62" overflow="linebreak"><mrow><msubsup><mi>s</mi><mi>i</mi><mo>″</mo></msubsup></mrow></math></span> represents the signal-reconstructed value (predicted value). In the first experiment, we determine the optimal depth of encoder-decoder modules. We design three encoder module structures, whose encoder-decoder depths equal 2, 3, and 4, respectively, and the corresponding neural networks are called DRdA-CA2, DRdA-CA3, and DRdA-CA4, respectively. The training loss and validation loss of the three network models are shown in <a href="#sensors-23-01023-f005" class="usa-link">Figure 5</a>. The detailed value of the training loss with different epochs and the numbers of parameters are listed in <a href="#sensors-23-01023-t003" class="usa-link">Table 3</a>. In terms of the training loss, DRdA-CA3 is 1.4–1.9% lower than DRdA-CA2 on average when the epoch is larger than 10, and the validation loss presents a similar trend. It should be noted that the performance of DRdA-CA3 and DRdA-CA4 is almost the same. When it comes to the complexity, the size of the model parameters of DRdA-CA2, DRdA-CA3, and DRdA-CA4 are 181 k, 263 k, and 345 k, respectively. Therefore, considering both the loss and model complexity, we choose DRdA-CA3 as the neural network model structure for the denoising tasks. Although the loss values have been small at the epoch equaling 10, they continue to decline and basically stabilize at 40 rounds. In this paper, the model parameters adopt the training results of 40 rounds.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f005"><h4 class="obj_head">Figure 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g005.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/7041e4abc00a/sensors-23-01023-g005.jpg" loading="lazy" height="632" width="788" alt="Figure 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Classification accuracy at different depths.</p></figcaption></figure><section class="tw xbox font-sm" id="sensors-23-01023-t003"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>The Parameters of Different Depths.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Model</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Parameter</th>
</tr></thead>
<tbody>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">DRdA-CA2</td>
<td align="center" valign="middle" rowspan="1" colspan="1">181,408</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">DRdA-CA3</td>
<td align="center" valign="middle" rowspan="1" colspan="1">263,416</td>
</tr>
<tr>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">DRdA-CA4</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">345,424</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/sensors-23-01023-t003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec5dot2-sensors-23-01023"><h3 class="pmc_sec_title">5.2. Ablation Experiments</h3>
<p>In this paper, the SE module is first improved and then introduced into the encoder as the channel attention module, so that the modulation signal features can be better extracted and the computational complexity of the model can be reduced. In order to validate the efficiency of the improved SE module as the channel attention mechanism, we carry out the first ablation experiment based on the control variable method. We compare the improved SE module (impr-SE) using the convolutional layer with the original SE module (orig-SE) using FC and the denoising autoencoder without a channel attention mechanism (withoutCA). In this case, the SE module is removed in the coding block in <a href="#sensors-23-01023-f003" class="usa-link">Figure 3</a>b. <a href="#sensors-23-01023-f006" class="usa-link">Figure 6</a>a displays the training loss (tra-loss) and validation loss (val-loss) of the three methods. As is shown, the module with the improved SE module gives better performance. When the epoch equals 40, it lower the validation loss by 35.7% and 17.9% compared to the module with the original SE and the model without a channel attention mechanism. In addition, it should be noted that the denoising model without a channel attention mechanism is even superior to the model with the original SE. This can be attributed to the loss of feature information caused by data dimension transformation. Therefore, a mismatched channel attention module may cause network performance degradation, and the improved SE is quite effective.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f006"><h4 class="obj_head">Figure 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g006.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/a4ed412620d6/sensors-23-01023-g006.jpg" loading="lazy" height="325" width="756" alt="Figure 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Ablation experiments. (<strong>a</strong>) Original SE and improved SE. (<strong>b</strong>) Single and dual residual connections.</p></figcaption></figure><p>In the proposed DRdA-CA, “dual” represents the residual connections added not only between different encoding (decoding) blocks but also inside the encoding (decoding) blocks of different depths, so it is called “dual”. In contrast, “single” refers to the residual connection only existing inside the encoding (decoding) block, and each encoding (decoding) block is the improved SE-ResNet module, which contains one residual connection. In order to demonstrate the advantages of “dual residual connections”, one of the main innovations, we have also conducted an ablation experiment based on the control variable method, comparing it with the “single residual connection” method, where the residual connection only exists inside the encoding (decoding) block. The loss curves are given in <a href="#sensors-23-01023-f006" class="usa-link">Figure 6</a>b. As shown in the figure, the dual residual model achieves a lower training loss and validation loss than the single residual model. When the epoch increases to 40, the validation loss of the dual residual connections is only 50% of that of the single residual connection. Comparing <a href="#sensors-23-01023-f006" class="usa-link">Figure 6</a>a,b, apparently, both the improved SE module and dual residual connections play an important role in improving denoising performance, and dual residual connections are more effective.</p></section><section id="sec5dot3-sensors-23-01023"><h3 class="pmc_sec_title">5.3. Comparison of SNR Improvement</h3>
<p>In the second experiment, we compare the SNR and EVM variations of different denoising methods. <a href="#sensors-23-01023-t004" class="usa-link">Table 4</a> displays the average values of SNR improvement in overall SNR, ranging from −12 dB to 8 dB for all eight modulation modes with five different denoising methods. In the SNR range of −12 dB to 8 dB, taking the GMSK signal as an example, the SNRs of the modulation signal are increased by 6.76 dB, 6.5 dB, and 7.18 dB, respectively, on average, after denoising with RLS, LMS, and PCA algorithms. When the DnCNN model is used for noise reduction, the SNRs of the signal are improved by 11.59 dB on average. Remarkably, the proposed DRdA-CA brings an increase of 16.8 dB on average in terms of the SNRs. When DRdA-CA is applied to 8PSK, 16QAM, and 64QAM signals, the average values of SNR enhancement are 9.47 dB, 8.38 dB, and 8.27 dB, respectively. For two deep learning-based denoising methods, DnCNN and DRdA-CA, the average values of SNR improvement gradually go up with the decrease in modulation order, except in a few cases. However, traditional noise reduction methods do not show similar laws. It is clear that DRdA-CA outperforms the DnCNN method and RLS, LMS, and PCA. This can be attributed to the well-designed structure in the proposed method, in which both double-residual connections and the introduction and improvement of the SE module contribute to a desirable denoising effect.</p>
<section class="tw xbox font-sm" id="sensors-23-01023-t004"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Average value of SNR improvement under different denoising methods.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">RLS</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LMS</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">PCA</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">DnCNN</th>
<th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">DRdA-CA</th>
</tr></thead>
<tbody>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">GMSK</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.76 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.50 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">7.18 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">11.59 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">16.84 dB</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">CPFSK</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.14 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.75 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">8.45 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">10.11 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">15.39 dB</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">BPSK</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.15 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.74 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">8.46 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">11.12 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">11.86 dB</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">QPSK</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.14 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.74 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.21 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">9.17 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">13.44 dB</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">OQPSK</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.14 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.76 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.17 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">8.99 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">13.43 dB</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">8PSK</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.13 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.74 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.44 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">8.29 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">9.47 dB</td>
</tr>
<tr>
<td align="center" valign="middle" rowspan="1" colspan="1">16QAM</td>
<td align="center" valign="middle" rowspan="1" colspan="1">6.13 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.75 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">5.43 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">7.9 dB</td>
<td align="center" valign="middle" rowspan="1" colspan="1">8.38 dB</td>
</tr>
<tr>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64QAM</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6.14 dB</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.78 dB</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6.19 dB</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7.79 dB</td>
<td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8.27 dB</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/sensors-23-01023-t004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>It would be complicated to use curves to display dynamic ranges of SNR and EVM after denoising with the increase of SNR for all eight modulation modes. As a result, we only present four typical modulation modes in <a href="#sensors-23-01023-f007" class="usa-link">Figure 7</a> and <a href="#sensors-23-01023-f008" class="usa-link">Figure 8</a>. <a href="#sensors-23-01023-f007" class="usa-link">Figure 7</a>a–d respectively show the SNR variations of GMSK, 8PSK, 16QAM, and 64QAM, and four signals are processed using different denoising methods. It can be seen from <a href="#sensors-23-01023-f007" class="usa-link">Figure 7</a> that the deep learning denoising methods, denoted as DRdA-CA and DnCNN, are superior to the three traditional denoising methods, denoted as LMS, RLS, and PCA. The proposed denoising method achieves different denoising effects for different modulation modes. Although denoising is more challenging for high-order modulation due to the complex signal patterns, the proposed denoising achieves a desirable denoising performance for high-order modulation. Moreover, for the four modulation types, the proposed DRdA-CA has always maintained the maximum SNR improvement over the entire SNR range.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f007"><h4 class="obj_head">Figure 7.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g007.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/110a9d986b0f/sensors-23-01023-g007.jpg" loading="lazy" height="679" width="767" alt="Figure 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f007/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>SNR of modulation signal after denoising [<a href="#B2-sensors-23-01023" class="usa-link" aria-describedby="B2-sensors-23-01023">2</a>,<a href="#B3-sensors-23-01023" class="usa-link" aria-describedby="B3-sensors-23-01023">3</a>,<a href="#B5-sensors-23-01023" class="usa-link" aria-describedby="B5-sensors-23-01023">5</a>,<a href="#B6-sensors-23-01023" class="usa-link" aria-describedby="B6-sensors-23-01023">6</a>,<a href="#B7-sensors-23-01023" class="usa-link" aria-describedby="B7-sensors-23-01023">7</a>,<a href="#B18-sensors-23-01023" class="usa-link" aria-describedby="B18-sensors-23-01023">18</a>]. (<strong>a</strong>) GMSK. (<strong>b</strong>) 8PSK. (<strong>c</strong>) 16QAM. (<strong>d</strong>) 64QAM.</p></figcaption></figure><figure class="fig xbox font-sm" id="sensors-23-01023-f008"><h4 class="obj_head">Figure 8.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g008.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/d109769ea031/sensors-23-01023-g008.jpg" loading="lazy" height="658" width="757" alt="Figure 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f008/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>EVM after denoising of modulation signal [<a href="#B2-sensors-23-01023" class="usa-link" aria-describedby="B2-sensors-23-01023">2</a>,<a href="#B3-sensors-23-01023" class="usa-link" aria-describedby="B3-sensors-23-01023">3</a>,<a href="#B5-sensors-23-01023" class="usa-link" aria-describedby="B5-sensors-23-01023">5</a>,<a href="#B6-sensors-23-01023" class="usa-link" aria-describedby="B6-sensors-23-01023">6</a>,<a href="#B7-sensors-23-01023" class="usa-link" aria-describedby="B7-sensors-23-01023">7</a>,<a href="#B18-sensors-23-01023" class="usa-link" aria-describedby="B18-sensors-23-01023">18</a>]. (<strong>a</strong>) GMSK. (<strong>b</strong>) 8PSK. (<strong>c</strong>) 16QAM. (<strong>d</strong>) 64QAM.</p></figcaption></figure><p><a href="#sensors-23-01023-f008" class="usa-link">Figure 8</a>a–d also show the EVM curves of the above four modulation signals processed using different noise reduction methods. The lower the EVM, the better the noise reduction performance. As seen from <a href="#sensors-23-01023-f008" class="usa-link">Figure 8</a>, the EVMs obtained using the two deep learning-based denoising methods are significantly lower than those obtained using the other three traditional denoising methods. After PCA denoising, the EVMs of the signals do not steadily decline with the increase in the SNR, which indicates that the robustness of PCA is poor. The signal EVM curves obtained after RLS and LMS denoising are close to each other when the SNR is greater than 4 dB. However, when the SNR falls in −12 dB∼4 dB, RLS is better than LMS. The deep learning algorithm DnCNN performs better than the three traditional algorithms do, and the proposed DRdA-CA makes a better achievement in denoising than DnCNN does.</p></section><section id="sec5dot4-sensors-23-01023"><h3 class="pmc_sec_title">5.4. Comparison of AMC Performance</h3>
<p>For non-cooperative communication applications, the receiver needs to firstly perform modulation classification, followed by demodulation and decoding. Therefore, the modulation classification experiment is also done to further verify the performance of the denoising autoencoder. The LMS and RLS algorithms need to know the modulation mode and send the training sequence when they are used to reduce noise in communication systems, leading to low transmission efficiency. Thus, they are unsuitable for non-cooperative communication applications. PCA also has the lowest denoising performance. As a result, in the experiment of the noise reduction cascade AMC, we compare the DnCNN to the proposed method. Moreover, the CNN [<a href="#B34-sensors-23-01023" class="usa-link" aria-describedby="B34-sensors-23-01023">34</a>] is adopted to implement AMC, and the dataset is given in <a href="#sec4dot1-sensors-23-01023" class="usa-link">Section 4.1</a>, including eight modulation signals under eleven SNRs.</p>
<p>The experiment schemes are as follows. (1) The CNN model is used for AMC directly, denoted as CNN. (2) The DnCNN method is used to reduce the noise of modulation signals, and then CNN is used for AMC, denoted as DnCNN+CNN. (3) The proposed DRdA-CA is used to decrease the noise, followed by CNN for AMC, denoted as DRdA-CA+CNN. <a href="#sensors-23-01023-f009" class="usa-link">Figure 9</a> displays the average classification accuracy of all the modulation modes for three different schemes. The modulation recognition accuracy is greatly increased when using denoising methods based on deep learning. The DRdA-CA method clearly outperforms the DnCNN method. When the SNR varies from −12 dB to 8 dB, compared with the non-denoising scheme, the scheme with DnCNN denoising improves the average classification accuracy by 0.01%∼12.5%. After using the proposed denoising approach, the average classification accuracy is increased by 1.88%∼29.25%. Compared to the DnCNN denoising method, the proposed DRdA-CA makes the average classification accuracy increase from 67.59%∼74.94% over the entire SNR range, which further shows the superiority of the proposed method.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f009"><h4 class="obj_head">Figure 9.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g009.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/68badc812071/sensors-23-01023-g009.jpg" loading="lazy" height="642" width="798" alt="Figure 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f009/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Modulation classification accuracy under different deep learning networks.</p></figcaption></figure><p><a href="#sensors-23-01023-f010" class="usa-link">Figure 10</a>a,b give the recognition accuracy of each modulation type with the latter two schemes. As seen in <a href="#sensors-23-01023-f010" class="usa-link">Figure 10</a>a, after DnCNN denoising, the recognition accuracy of the three low-order modulations, BPSK, GMSK, and CPFSK, is relatively high, and almost reaches 100% under the SNR of −4 dB. This is because these three types are low-order modulations and the patterns of the signals are simple and significantly different from those of the high-order PSK and QAM. Therefore, their classification accuracy is also high, even through general DnCNN denoising.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f010"><h4 class="obj_head">Figure 10.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g010.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/cc0e7f905128/sensors-23-01023-g010.jpg" loading="lazy" height="317" width="773" alt="Figure 10"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f010/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Classification accuracy of different networks for each modulation type. (<strong>a</strong>) DnCNN+CNN. (<strong>b</strong>) DRdA-CA+CNN.</p></figcaption></figure><p>However, the recognition performance of the high-order modulations is poor. In particular, the recognition accuracy of the 16QAM and 64QAM signals fluctuates widely. This is attributed to the highly similar characteristics of higher-order modulation signals and the insufficient noise reduction capability of DnCNN. It should be noted that the classification accuracy of QPSK and OQPSK is lower than that of 8PSK in most of the SNR intervals, although their modulation order is smaller than that of 8PSK. This is because the QPSK and OQPSK signal patterns are too similar, and they are very easy to confuse when the noise reduction effect is limited with the DnCNN method.</p>
<p>According to the <a href="#sensors-23-01023-f010" class="usa-link">Figure 10</a>b, DRdA-CA denoising makes the recognition accuracy of each modulation signal increase significantly. Although 16QAM and 64QAM still cannot achieve accurate classification when the SNR is larger than 2 dB, their recognition accuracy exhibits a continuous rising trend with an increase in the SNR. It demonstrates that the strong denoising ability of the proposed DRdA-CA is beneficial for AMC. The classification accuracy of 16QAM and 64QAM can be further improved by adopting better modulation classification model after denoising, and this paper focuses on the design of the denoising network.</p></section><section id="sec5dot5-sensors-23-01023"><h3 class="pmc_sec_title">5.5. Comparison of Demodulation Performance</h3>
<p>In order to further verify the performance of the proposed DRdA-CA, the demodulation experiments after denoising have also been done. We present two higher-order modulation modes, 16QAM and 64QAM, since their demodulations are more challenging in the low SNR range for practical communication systems. The RLS algorithm with better performance in the traditional methods and the DnCNN are selected as the comparison methods. <a href="#sensors-23-01023-f011" class="usa-link">Figure 11</a> shows the BER curves of demodulation for the 16QAM and 64QAM signals after denoising with different methods.</p>
<figure class="fig xbox font-sm" id="sensors-23-01023-f011"><h4 class="obj_head">Figure 11.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=9861137_sensors-23-01023-g011.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c91f/9861137/d1790103e5da/sensors-23-01023-g011.jpg" loading="lazy" height="622" width="769" alt="Figure 11"></a></p>
<div class="p text-right font-secondary"><a href="figure/sensors-23-01023-f011/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Demodulation BER after denoising.</p></figcaption></figure><p>From <a href="#sensors-23-01023-f011" class="usa-link">Figure 11</a>, it can be seen that the three noise reduction methods can improve the BER performance of signal demodulation. The DnCNN improves BER more than the traditional RLS, and the proposed DRdA-CA considerably outperforms both of these two methods. When the SNR ranges from −12 dB to 8 dB, the proposed method decreases the BER by 22.3%∼99.5% for 16QAM and 12.6%∼93.7% for 64QAM compared to the non-denoising method. In addition, compared with RLS and DnCNN, DRdA-CA reduces the BER of 16QAM by 63.5% and 40.5% on average, and makes the BER of 64QAM decline by 46.7% and 18.6% on average, across the entire SNR range. For 16QAM signals at an SNR of 8 dB, when using the RLS and DRdA-CA, the BER of demodulation is reduced by two orders of magnitude, from 0.05 to 0.0005. Besides, compared with DnCNN, the BER of DRdA-CA is only 1/6 of the former. When it comes to the 64QAM signals at an SNR of 8 dB, compared with the non-denoising method, DRdA-CA makes BER decrease from 0.195 to 0.0123, and compared to the RLS and the DnCNN, it reduces the BER of 64QAM by 91.49% and 43.34%, respectively.</p></section></section><section id="sec6-sensors-23-01023"><h2 class="pmc_sec_title">6. Conclusions</h2>
<p>In this paper, a dual residual denoising autoencoder with channel attention (DRdA-CA) is designed based on CNN to deal with the problems caused by a low SNR in wireless communications. First, as a channel attention mechanism, the SE module with one residual connection is adapted and applied to the proposed DRdA-CA to improve the feature extraction ability of neural networks. Then, the other residual connection between the different coding (decoding) blocks is introduced to solve the network degradation problem, which promotes the fusion of model characteristic information at different depths, and further enhances the network noise reduction performance. Moreover, a dataset including eight modulation types is created under the AWGN channel model.</p>
<p>The ablation experiments are done to verify the efficiency of the improved SE module and the dual residual connections, and the dual residual connections are more helpful in improving the denoising performance. Then, the experiments on SNR improvement, modulation classification, and demodulation are also done to verify the advantage of the proposed method. The simulation results show that the proposed DRdA-CA surpasses the traditional denoising algorithms and the DnCNN noise reduction method in both improving the SNR and recovering the original signals for all eight modulation modes. Taking GMSK and 8PSK as examples, the proposed DRdA-CA improves the SNR by 16.84 dB and 9.47 dB on average, respectively. Compared to the DnCNN denoising method, the proposed DRdA-CA makes the recognition accuracy of each modulation signal increase significantly. Even the recognition accuracy of 16QAM and 64QAM goes up steadily with the increase in the SNR. Besides, demodulation performance is also dramatically improved after using the proposed DRdA-CA to reduce noise. Taking the SNR of 8 dB as an example, for 64QAM signals, the proposed DRdA-CA lowers BER by 43.34% compared to the DnCNN method. These experiments further demonstrate our method’s strength. In the future, we will extend our designs and make it suitable for the fading-channel scenario, where modulation signals are prone to be affected by multipath propagation and the Doppler frequency shift.</p></section><section id="glossary1" class="glossary"><h2 class="pmc_sec_title">Abbreviations</h2>
<p>The following abbreviations are used in this manuscript:
</p>
<section class="tw xbox font-sm" id="array1"><div class="tbl-box p" tabindex="0"><table class="content">
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">BER</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Bit Error Rate</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">SNR</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Signal-to-Noise Ratio</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">DRdA-CA</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Double-Residual Denoising Autoencoder Method with Channel Attention Mechanism</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">WT</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Wavelet Transform</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">LMS</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Least Mean Square</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">RLS</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Recursive Least Squares</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">PCA</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Principal Component Analysis</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">SVD</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Singular Value Decomposition</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">CNN</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Convolutional Neural Network</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">FC</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Fully Connected Layers</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">ML</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Machine Learning</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">VKF</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Vector Kalman Filter</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">SCM</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Spatial Channel Model</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">DnCNN</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Residual Learning of Deep CNN for Image Denoising</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">SE</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Squeeze-and-Excitation</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">TConv</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Transpose Convolution</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">SLL</td>
<td align="left" valign="middle" rowspan="1" colspan="1">SmoothL1Loss</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">AWGN</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Additive White Gaussin Noise</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">AMC</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Automatic Modulation Classification</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">SE-ResNet</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Squeeze-and-Excitation Deep Residual Networks</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">ResNet</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Deep Residual Network</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">GAP</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Global Average Pooling</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">MAE</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Mean Absolute Error</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">MSE</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Mean Square Error</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">Adam</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Adaptive Moment Estimation</td>
</tr>
<tr>
<td align="left" valign="middle" rowspan="1" colspan="1">EVM</td>
<td align="left" valign="middle" rowspan="1" colspan="1">Error Vector Magnitude</td>
</tr>
</table></div>
<div class="p text-right font-secondary"><a href="table/array1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="notes1"><h2 class="pmc_sec_title">Author Contributions</h2>
<p>Conceptualization, R.D. and Z.C.; methodology, R.D. and H.Z.; validation, R.D., Z.C. and H.Z.; formal analysis, H.Z. and X.W.; investigation, G.S.; resources, W.M.; data curation, Z.C.; writing—original draft preparation, R.D. and X.W.; writing—review and editing, Z.C. and W.M.; visualization, H.Z. and G.S.; supervision, W.M.; project administration, R.D. and H.Z.; funding acquisition, R.D. All authors have read and agreed to the published version of the manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Institutional Review Board Statement</h2>
<p>Not applicable.</p></section><section id="notes3"><h2 class="pmc_sec_title">Informed Consent Statement</h2>
<p>Not applicable.</p></section><section id="notes4"><h2 class="pmc_sec_title">Data Availability Statement</h2>
<p>The dataset is available from the website <a href="https://github.com/GJX2810/moddataset.git" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/GJX2810/moddataset.git</a> (accessed on 14 November 2022).</p></section><section id="notes5"><h2 class="pmc_sec_title">Conflicts of Interest</h2>
<p>The authors declare no conflict of interest.</p></section><section id="funding-statement1" lang="en"><h2 class="pmc_sec_title">Funding Statement</h2>
<p>The work was supported by the Fundamental Research Funds for the Central Universities (BLX201623), Beijing Natural Science Foundation (L202003) and National Natural Science Foundation of China (No.31700479).</p></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm"><div class="fn p" id="fn1"><p><strong>Disclaimer/Publisher’s Note:</strong> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></div></div></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="B1-sensors-23-01023">
<span class="label">1.</span><cite>Parolai S. Denoising of Seismograms Using the S Transform. Bull. Seismol. Soc. Am. 2009;99:226–234. doi: 10.1785/0120080001.</cite> [<a href="https://doi.org/10.1785/0120080001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Bull.%20Seismol.%20Soc.%20Am.&amp;title=Denoising%20of%20Seismograms%20Using%20the%20S%20Transform&amp;author=S.%20Parolai&amp;volume=99&amp;publication_year=2009&amp;pages=226-234&amp;doi=10.1785/0120080001&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B2-sensors-23-01023">
<span class="label">2.</span><cite>Milani A.A., Panahi I.M.S., Briggs R.W. LMS-Based Active Noise Cancellation Methods for fMRI Using Sub-band Filtering; Proceedings of the 2006 International Conference of the IEEE Engineering in Medicine and Biology Society; New York, NY, USA. 30 August–3 September 2006; pp. 513–516.</cite> [<a href="https://doi.org/10.1109/IEMBS.2006.259731" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17946837/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202006%20International%20Conference%20of%20the%20IEEE%20Engineering%20in%20Medicine%20and%20Biology%20Society&amp;title=LMS-Based%20Active%20Noise%20Cancellation%20Methods%20for%20fMRI%20Using%20Sub-band%20Filtering&amp;author=A.A.%20Milani&amp;author=I.M.S.%20Panahi&amp;author=R.W.%20Briggs&amp;pages=513-516&amp;pmid=17946837&amp;doi=10.1109/IEMBS.2006.259731&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B3-sensors-23-01023">
<span class="label">3.</span><cite>Albu F., Paleologu C. A recursive least square algorithm for active noise control based on the Gauss-Seidel method; Proceedings of the 2008 15th IEEE International Conference on Electronics, Circuits and Systems; St. Julian’s, Malta. 31 August–3 September 2008; pp. 830–833.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202008%2015th%20IEEE%20International%20Conference%20on%20Electronics,%20Circuits%20and%20Systems&amp;title=A%20recursive%20least%20square%20algorithm%20for%20active%20noise%20control%20based%20on%20the%20Gauss-Seidel%20method&amp;author=F.%20Albu&amp;author=C.%20Paleologu&amp;pages=830-833&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B4-sensors-23-01023">
<span class="label">4.</span><cite>Haykin S.  Adaptive Filter Theory. Pearson Education; Upper Saddle River, NJ, USA: 1986. </cite> [<a href="https://scholar.google.com/scholar_lookup?title=Adaptive%20Filter%20Theory&amp;author=S.%20Haykin&amp;publication_year=1986&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B5-sensors-23-01023">
<span class="label">5.</span><cite>Li X.L., Anderson M., Adalı T. Principal component analysis for noncircular signals in the presence of circular white gaussian noise; Proceedings of the 2010 Conference Record of the Forty Fourth Asilomar Conference on Signals, Systems and Computers; Pacific Grove, CA, USA. 7–10 November 2010; pp. 1796–1801.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202010%20Conference%20Record%20of%20the%20Forty%20Fourth%20Asilomar%20Conference%20on%20Signals,%20Systems%20and%20Computers&amp;title=Principal%20component%20analysis%20for%20noncircular%20signals%20in%20the%20presence%20of%20circular%20white%20gaussian%20noise&amp;author=X.L.%20Li&amp;author=M.%20Anderson&amp;author=T.%20Adal%C4%B1&amp;pages=1796-1801&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B6-sensors-23-01023">
<span class="label">6.</span><cite>Pyatykh S., Hesser J.W., Zheng L. Image Noise Level Estimation by Principal Component Analysis. IEEE Trans. Image Process. 2013;22:687–699. doi: 10.1109/TIP.2012.2221728.</cite> [<a href="https://doi.org/10.1109/TIP.2012.2221728" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23033431/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Image%20Process.&amp;title=Image%20Noise%20Level%20Estimation%20by%20Principal%20Component%20Analysis&amp;author=S.%20Pyatykh&amp;author=J.W.%20Hesser&amp;author=L.%20Zheng&amp;volume=22&amp;publication_year=2013&amp;pages=687-699&amp;pmid=23033431&amp;doi=10.1109/TIP.2012.2221728&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B7-sensors-23-01023">
<span class="label">7.</span><cite>Zhao Q., Meng D., Xu Z., Zuo W., Zhang L. Robust Principal Component Analysis with Complex Noise; Proceedings of the ICML; Beijing, China. 21–26 June 2014.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%20ICML&amp;title=Robust%20Principal%20Component%20Analysis%20with%20Complex%20Noise&amp;author=Q.%20Zhao&amp;author=D.%20Meng&amp;author=Z.%20Xu&amp;author=W.%20Zuo&amp;author=L.%20Zhang&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B8-sensors-23-01023">
<span class="label">8.</span><cite>Peng F., Gao Y. Noise reduction of BPSK signals based on convolutional self-coding networks. Inf. Commun. 2020;8:41–44.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Inf.%20Commun.&amp;title=Noise%20reduction%20of%20BPSK%20signals%20based%20on%20convolutional%20self-coding%20networks&amp;author=F.%20Peng&amp;author=Y.%20Gao&amp;volume=8&amp;publication_year=2020&amp;pages=41-44&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B9-sensors-23-01023">
<span class="label">9.</span><cite>Bekara M., van der Baan M. Local singular value decomposition for signal enhancement of seismic data. Geophysics. 2007;72:V59–V65. doi: 10.1190/1.2435967.</cite> [<a href="https://doi.org/10.1190/1.2435967" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Geophysics&amp;title=Local%20singular%20value%20decomposition%20for%20signal%20enhancement%20of%20seismic%20data&amp;author=M.%20Bekara&amp;author=M.%20van%20der%20Baan&amp;volume=72&amp;publication_year=2007&amp;pages=V59-V65&amp;doi=10.1190/1.2435967&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B10-sensors-23-01023">
<span class="label">10.</span><cite>Rajwade A., Rangarajan A., Banerjee A. Image Denoising Using the Higher Order Singular Value Decomposition. IEEE Trans. Pattern Anal. Mach. Intell. 2013;35:849–862. doi: 10.1109/TPAMI.2012.140.</cite> [<a href="https://doi.org/10.1109/TPAMI.2012.140" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/22732660/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Pattern%20Anal.%20Mach.%20Intell.&amp;title=Image%20Denoising%20Using%20the%20Higher%20Order%20Singular%20Value%20Decomposition&amp;author=A.%20Rajwade&amp;author=A.%20Rangarajan&amp;author=A.%20Banerjee&amp;volume=35&amp;publication_year=2013&amp;pages=849-862&amp;pmid=22732660&amp;doi=10.1109/TPAMI.2012.140&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B11-sensors-23-01023">
<span class="label">11.</span><cite>Zhang G., He H., Zhang P. NR-MC-CDSK Chaotic Communication System Based on Schmidt Orthogonalization. J. Electron. Inf. Technol. 2021;43:1930–1938.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=J.%20Electron.%20Inf.%20Technol.&amp;title=NR-MC-CDSK%20Chaotic%20Communication%20System%20Based%20on%20Schmidt%20Orthogonalization&amp;author=G.%20Zhang&amp;author=H.%20He&amp;author=P.%20Zhang&amp;volume=43&amp;publication_year=2021&amp;pages=1930-1938&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B12-sensors-23-01023">
<span class="label">12.</span><cite>Chang Z., Wang Y., Li H., Wang Z. Complex CNN-Based Equalization for Communication Signal; Proceedings of the 2019 IEEE 4th International Conference on Signal and Image Processing (ICSIP); Wuxi, China. 19–21 July 2019; pp. 513–517.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202019%20IEEE%204th%20International%20Conference%20on%20Signal%20and%20Image%20Processing%20(ICSIP)&amp;title=Complex%20CNN-Based%20Equalization%20for%20Communication%20Signal&amp;author=Z.%20Chang&amp;author=Y.%20Wang&amp;author=H.%20Li&amp;author=Z.%20Wang&amp;pages=513-517&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B13-sensors-23-01023">
<span class="label">13.</span><cite>Wada T., Toma T., Dawodi M., Baktash J.A. A Denoising Autoencoder based wireless channel transfer function estimator for OFDM communication system; Proceedings of the 2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC); Okinawa, Japan. 11–13 February 2019; pp. 530–533.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202019%20International%20Conference%20on%20Artificial%20Intelligence%20in%20Information%20and%20Communication%20(ICAIIC)&amp;title=A%20Denoising%20Autoencoder%20based%20wireless%20channel%20transfer%20function%20estimator%20for%20OFDM%20communication%20system&amp;author=T.%20Wada&amp;author=T.%20Toma&amp;author=M.%20Dawodi&amp;author=J.A.%20Baktash&amp;pages=530-533&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B14-sensors-23-01023">
<span class="label">14.</span><cite>Zhao T., Zhong Y., Wang Y. Parallel multi-scale CNN for image denoising; Proceedings of the 5th International Conference on Communication and Information Processing (ICCIP ’19); Chongqing, China. 15–17 November 2019.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%205th%20International%20Conference%20on%20Communication%20and%20Information%20Processing%20(ICCIP%20%E2%80%9919)&amp;title=Parallel%20multi-scale%20CNN%20for%20image%20denoising&amp;author=T.%20Zhao&amp;author=Y.%20Zhong&amp;author=Y.%20Wang&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B15-sensors-23-01023">
<span class="label">15.</span><cite>Rock J., Tóth M., Meissner P., Pernkopf F. Deep Interference Mitigation and Denoising of Real-World FMCW Radar Signals; Proceedings of the 2020 IEEE International Radar Conference (RADAR); Washington, DC, USA. 28–30 April 2020; pp. 624–629.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202020%20IEEE%20International%20Radar%20Conference%20(RADAR)&amp;title=Deep%20Interference%20Mitigation%20and%20Denoising%20of%20Real-World%20FMCW%20Radar%20Signals&amp;author=J.%20Rock&amp;author=M.%20T%C3%B3th&amp;author=P.%20Meissner&amp;author=F.%20Pernkopf&amp;pages=624-629&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B16-sensors-23-01023">
<span class="label">16.</span><cite>Kim H., Kim S., Lee H., Choi J. Massive MIMO Channel Prediction: Machine Learning Versus Kalman Filtering; Proceedings of the 2020 IEEE Globecom Workshops (GC Wkshps); Taipei, Taiwan. 7–11 December 2020; pp. 1–6.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202020%20IEEE%20Globecom%20Workshops%20(GC%20Wkshps)&amp;title=Massive%20MIMO%20Channel%20Prediction:%20Machine%20Learning%20Versus%20Kalman%20Filtering&amp;author=H.%20Kim&amp;author=S.%20Kim&amp;author=H.%20Lee&amp;author=J.%20Choi&amp;pages=1-6&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B17-sensors-23-01023">
<span class="label">17.</span><cite>Zhang K., Zuo W., Chen Y., Meng D., Zhang L. Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising. IEEE Trans. Image Process. 2017;26:3142–3155. doi: 10.1109/TIP.2017.2662206.</cite> [<a href="https://doi.org/10.1109/TIP.2017.2662206" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28166495/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Image%20Process.&amp;title=Beyond%20a%20Gaussian%20Denoiser:%20Residual%20Learning%20of%20Deep%20CNN%20for%20Image%20Denoising&amp;author=K.%20Zhang&amp;author=W.%20Zuo&amp;author=Y.%20Chen&amp;author=D.%20Meng&amp;author=L.%20Zhang&amp;volume=26&amp;publication_year=2017&amp;pages=3142-3155&amp;pmid=28166495&amp;doi=10.1109/TIP.2017.2662206&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B18-sensors-23-01023">
<span class="label">18.</span><cite>Khan S., Khan K.S., Shin S.Y.K. Symbol Denoising in High Order M-QAM using Residual learning of Deep CNN; Proceedings of the 2019 16th IEEE Annual Consumer Communications &amp; Networking Conference (CCNC); Las Vegas, NV, USA. 11–14 January 2019; pp. 1–6.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202019%2016th%20IEEE%20Annual%20Consumer%20Communications%20&amp;%20Networking%20Conference%20(CCNC)&amp;title=Symbol%20Denoising%20in%20High%20Order%20M-QAM%20using%20Residual%20learning%20of%20Deep%20CNN&amp;author=S.%20Khan&amp;author=K.S.%20Khan&amp;author=S.Y.K.%20Shin&amp;pages=1-6&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B19-sensors-23-01023">
<span class="label">19.</span><cite>Yin J., Luo W., Li L., Han X., Guo L., Wang J. Enhancement of underwater acoustic signal based on denoising automatic-encoder. J. Commun. 2019;40:119–126.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=J.%20Commun.&amp;title=Enhancement%20of%20underwater%20acoustic%20signal%20based%20on%20denoising%20automatic-encoder&amp;author=J.%20Yin&amp;author=W.%20Luo&amp;author=L.%20Li&amp;author=X.%20Han&amp;author=L.%20Guo&amp;volume=40&amp;publication_year=2019&amp;pages=119-126&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B20-sensors-23-01023">
<span class="label">20.</span><cite>Zhou X., Sun Z., Wu H. Wireless signal enhancement based on generative adversarial networks. Ad. Hoc. Netw. 2020;103:102151. doi: 10.1016/j.adhoc.2020.102151.</cite> [<a href="https://doi.org/10.1016/j.adhoc.2020.102151" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Ad.%20Hoc.%20Netw.&amp;title=Wireless%20signal%20enhancement%20based%20on%20generative%20adversarial%20networks&amp;author=X.%20Zhou&amp;author=Z.%20Sun&amp;author=H.%20Wu&amp;volume=103&amp;publication_year=2020&amp;pages=102151&amp;doi=10.1016/j.adhoc.2020.102151&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B21-sensors-23-01023">
<span class="label">21.</span><cite>Jiang Y., Li H., Rangaswamy M. Deep Learning Denoising Based Line Spectral Estimation. IEEE Signal Process. Lett. 2019;26:1573–1577. doi: 10.1109/LSP.2019.2939049.</cite> [<a href="https://doi.org/10.1109/LSP.2019.2939049" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Signal%20Process.%20Lett.&amp;title=Deep%20Learning%20Denoising%20Based%20Line%20Spectral%20Estimation&amp;author=Y.%20Jiang&amp;author=H.%20Li&amp;author=M.%20Rangaswamy&amp;volume=26&amp;publication_year=2019&amp;pages=1573-1577&amp;doi=10.1109/LSP.2019.2939049&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B22-sensors-23-01023">
<span class="label">22.</span><cite>Jin K.H., McCann M.T., Froustey E., Unser M.A. Deep Convolutional Neural Network for Inverse Problems in Imaging. IEEE Trans. Image Process. 2017;26:4509–4522. doi: 10.1109/TIP.2017.2713099.</cite> [<a href="https://doi.org/10.1109/TIP.2017.2713099" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28641250/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Image%20Process.&amp;title=Deep%20Convolutional%20Neural%20Network%20for%20Inverse%20Problems%20in%20Imaging&amp;author=K.H.%20Jin&amp;author=M.T.%20McCann&amp;author=E.%20Froustey&amp;author=M.A.%20Unser&amp;volume=26&amp;publication_year=2017&amp;pages=4509-4522&amp;pmid=28641250&amp;doi=10.1109/TIP.2017.2713099&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B23-sensors-23-01023">
<span class="label">23.</span><cite>Wang Y., Tu L., Guo J., Wang Z. Residual learning based RF signal denoising; Proceedings of the 2018 IEEE International Conference on Applied System Invention (ICASI); Tokyo, Japan. 13–17 April 2018; pp. 15–18.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202018%20IEEE%20International%20Conference%20on%20Applied%20System%20Invention%20(ICASI)&amp;title=Residual%20learning%20based%20RF%20signal%20denoising&amp;author=Y.%20Wang&amp;author=L.%20Tu&amp;author=J.%20Guo&amp;author=Z.%20Wang&amp;pages=15-18&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B24-sensors-23-01023">
<span class="label">24.</span><cite>Wang Y., Huang H., Xu Q., Liu J., Liu Y., Wang J. Practical Deep Raw Image Denoising on Mobile Devices. arXiv. 20202010.06935</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=arXiv&amp;title=Practical%20Deep%20Raw%20Image%20Denoising%20on%20Mobile%20Devices&amp;author=Y.%20Wang&amp;author=H.%20Huang&amp;author=Q.%20Xu&amp;author=J.%20Liu&amp;author=Y.%20Liu&amp;publication_year=2020&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B25-sensors-23-01023">
<span class="label">25.</span><cite>Kang E., Chang W., Yoo J., Ye J.C. Deep Convolutional Framelet Denoising for Low-Dose CT via Wavelet Residual Network. IEEE Trans. Med. Imaging. 2018;37:1358–1369. doi: 10.1109/TMI.2018.2823756.</cite> [<a href="https://doi.org/10.1109/TMI.2018.2823756" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29870365/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Med.%20Imaging&amp;title=Deep%20Convolutional%20Framelet%20Denoising%20for%20Low-Dose%20CT%20via%20Wavelet%20Residual%20Network&amp;author=E.%20Kang&amp;author=W.%20Chang&amp;author=J.%20Yoo&amp;author=J.C.%20Ye&amp;volume=37&amp;publication_year=2018&amp;pages=1358-1369&amp;pmid=29870365&amp;doi=10.1109/TMI.2018.2823756&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B26-sensors-23-01023">
<span class="label">26.</span><cite>Casas L., Navab N., Belagiannis V. Adversarial Signal Denoising with Encoder-Decoder Networks; Proceedings of the 2020 28th European Signal Processing Conference (EUSIPCO); Amsterdam, The Netherlands. 18–21 January 2021; pp. 1467–1471.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202020%2028th%20European%20Signal%20Processing%20Conference%20(EUSIPCO)&amp;title=Adversarial%20Signal%20Denoising%20with%20Encoder-Decoder%20Networks&amp;author=L.%20Casas&amp;author=N.%20Navab&amp;author=V.%20Belagiannis&amp;pages=1467-1471&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B27-sensors-23-01023">
<span class="label">27.</span><cite>He K., Zhang X., Ren S., Sun J. Deep Residual Learning for Image Recognition; Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Las Vegas, NV, USA. 27–30 June 2016; pp. 770–778.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202016%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20(CVPR)&amp;title=Deep%20Residual%20Learning%20for%20Image%20Recognition&amp;author=K.%20He&amp;author=X.%20Zhang&amp;author=S.%20Ren&amp;author=J.%20Sun&amp;pages=770-778&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B28-sensors-23-01023">
<span class="label">28.</span><cite>Yancheng L., Zeng X., Dong Q., Wang X. RED-MAM: A residual encoder-decoder network based on multi-attention fusion for ultrasound image denoising. Biomed. Signal Process. Control. 2023;79:104062.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Biomed.%20Signal%20Process.%20Control&amp;title=RED-MAM:%20A%20residual%20encoder-decoder%20network%20based%20on%20multi-attention%20fusion%20for%20ultrasound%20image%20denoising&amp;author=L.%20Yancheng&amp;author=X.%20Zeng&amp;author=Q.%20Dong&amp;author=X.%20Wang&amp;volume=79&amp;publication_year=2023&amp;pages=104062&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B29-sensors-23-01023">
<span class="label">29.</span><cite>Li H., Qiu K., Chen L., Mei X., Hong L., Tao C. SCAttNet: Semantic Segmentation Network With Spatial and Channel Attention Mechanism for High-Resolution Remote Sensing Images. IEEE Geosci. Remote Sens. Lett. 2019;18:905–909. doi: 10.1109/LGRS.2020.2988294.</cite> [<a href="https://doi.org/10.1109/LGRS.2020.2988294" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Geosci.%20Remote%20Sens.%20Lett.&amp;title=SCAttNet:%20Semantic%20Segmentation%20Network%20With%20Spatial%20and%20Channel%20Attention%20Mechanism%20for%20High-Resolution%20Remote%20Sensing%20Images&amp;author=H.%20Li&amp;author=K.%20Qiu&amp;author=L.%20Chen&amp;author=X.%20Mei&amp;author=L.%20Hong&amp;volume=18&amp;publication_year=2019&amp;pages=905-909&amp;doi=10.1109/LGRS.2020.2988294&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B30-sensors-23-01023">
<span class="label">30.</span><cite>Zhou T., Canu S., Ruan S. Automatic COVID-19 CT segmentation using U-Net integrated spatial and channel attention mechanism. Int. J. Imaging Syst. Technol. 2020;31:16–27. doi: 10.1002/ima.22527.</cite> [<a href="https://doi.org/10.1002/ima.22527" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7753491/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33362345/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Int.%20J.%20Imaging%20Syst.%20Technol.&amp;title=Automatic%20COVID-19%20CT%20segmentation%20using%20U-Net%20integrated%20spatial%20and%20channel%20attention%20mechanism&amp;author=T.%20Zhou&amp;author=S.%20Canu&amp;author=S.%20Ruan&amp;volume=31&amp;publication_year=2020&amp;pages=16-27&amp;pmid=33362345&amp;doi=10.1002/ima.22527&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B31-sensors-23-01023">
<span class="label">31.</span><cite>Hu J., Shen L., Albanie S., Sun G., Wu E. Squeeze-and-Excitation Networks. IEEE Trans. Pattern Anal. Mach. Intell. 2020;42:2011–2023. doi: 10.1109/TPAMI.2019.2913372.</cite> [<a href="https://doi.org/10.1109/TPAMI.2019.2913372" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31034408/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Pattern%20Anal.%20Mach.%20Intell.&amp;title=Squeeze-and-Excitation%20Networks&amp;author=J.%20Hu&amp;author=L.%20Shen&amp;author=S.%20Albanie&amp;author=G.%20Sun&amp;author=E.%20Wu&amp;volume=42&amp;publication_year=2020&amp;pages=2011-2023&amp;pmid=31034408&amp;doi=10.1109/TPAMI.2019.2913372&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B32-sensors-23-01023">
<span class="label">32.</span><cite>Zhang Y., Li G., Lei J., He J. FF-CAM: Crowd counting based on frontend-backend fusion through channel-attention mechanism. Comput. Sci. 2020;44:304–317.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Comput.%20Sci.&amp;title=FF-CAM:%20Crowd%20counting%20based%20on%20frontend-backend%20fusion%20through%20channel-attention%20mechanism&amp;author=Y.%20Zhang&amp;author=G.%20Li&amp;author=J.%20Lei&amp;author=J.%20He&amp;volume=44&amp;publication_year=2020&amp;pages=304-317&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B33-sensors-23-01023">
<span class="label">33.</span><cite>Chirag B., Lohith A., Prasantha H.S. Comparative performance analysis of various digital modulation schemes in AWGN channel; Proceedings of the 2017 Innovations in Power and Advanced Computing Technologies (i-PACT); Vellore, India. 21–22 April 2017; pp. 1–5.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%202017%20Innovations%20in%20Power%20and%20Advanced%20Computing%20Technologies%20(i-PACT)&amp;title=Comparative%20performance%20analysis%20of%20various%20digital%20modulation%20schemes%20in%20AWGN%20channel&amp;author=B.%20Chirag&amp;author=A.%20Lohith&amp;author=H.S.%20Prasantha&amp;pages=1-5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="B34-sensors-23-01023">
<span class="label">34.</span><cite>O’Shea T., Corgan J., Clancy T.C. Convolutional Radio Modulation Recognition Networks. arXiv. 20161602.04105</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=arXiv&amp;title=Convolutional%20Radio%20Modulation%20Recognition%20Networks&amp;author=T.%20O%E2%80%99Shea&amp;author=J.%20Corgan&amp;author=T.C.%20Clancy&amp;publication_year=2016&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The dataset is available from the website <a href="https://github.com/GJX2810/moddataset.git" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/GJX2810/moddataset.git</a> (accessed on 14 November 2022).</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Sensors (Basel, Switzerland) are provided here courtesy of <strong>Multidisciplinary Digital Publishing Institute  (MDPI)</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.3390/s23021023"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/sensors-23-01023.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (994.7 KB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/9861137/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/9861137/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC9861137%2F%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC9861137/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC9861137/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC9861137/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/36679819/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC9861137/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/36679819/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC9861137/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/9861137/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="EI6EdBLbRIZnbJPCMVDXmMoBE4dcdXWYv1fJl0aqDNhctt5mMtxiThQAdxhqjgFF">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
